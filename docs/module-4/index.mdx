---
title: Module 4 - Vision-Language-Action & Capstone
---

# Module 4: Vision-Language-Action & Capstone

**Theme:** Cognition, Interaction, and Autonomy

This module focuses on advanced AI capabilities that enable humanoid robots to understand natural language commands, perceive their environment, and execute complex tasks autonomously.

## Overview

This module covers:
- Vision systems for humanoid robots
- Language as a control interface
- Vision-Language-Action (VLA) pipelines
- The autonomous humanoid capstone project

## Learning Objectives

After completing this module, students will be able to:
- Implement vision systems for robot perception
- Create language-to-action translation systems
- Design Vision-Language-Action pipelines with LLMs
- Integrate all components for the autonomous humanoid capstone

## Prerequisites

Students should have completed all previous modules, with knowledge of Physical AI fundamentals, ROS 2, and simulation systems.

## Capstone Alignment

This module culminates in the autonomous humanoid capstone project, integrating all concepts learned throughout the textbook.